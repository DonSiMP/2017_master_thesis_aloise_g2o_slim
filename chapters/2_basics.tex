\chapter{Basics}\label{ch:basics}
The goal of this chapter is to introduce the reader to the mathematical fundamentals underlying the system developed. Obviously, it will be a brief overview, therefore, references to literature are provided if the reader would like to go more in detail with the proposed concepts.

\section{Least Square SLAM}
In this section it proposed an insight of least-squares state estimation of non-linear stationary systems \cite{charnes1976least-squares}.

Suppose to have a stationary system $\mathcal{W}$ whose state is parametrized by a set of non-observable \textbf{state} variables $\mathbf{x} = \{\mathbf{x}_1, ..., \mathbf{x}_N\}$. Suppose that it is possible to indirectly observe the system state with different generic sensors, those will generate a set of \textbf{measurements} represented by $\mathbf{z} = \{\mathbf{z}_1, ..., \mathbf{z}_K\}$, where $\mathbf{z}_k$ is intended to be the $k^{th}$ measurement. Since the measurements are affected by noise, those are assumed to be \textbf{random variables}. Moreover, the state embeds all the knowledge needed to predict the measurements' distribution.

Since measurements are affected by noise, it is impossible to compute the state given the measurements. What is possible to evaluate, instead, is the states' distribution known the measurements, which can be formalized as following \textit{conditional probability}:

\begin{align} 
    p\left(\state | \meas\right) &= p\left(\state_1, ..., \state_N | \meas_1, ..., \meas_K\right) = \nonumber \\
    &= p\left(\state_{1:N} | \meas_{1:K}\right)
    \label{eq:cond_state_p}
\end{align}

The probability distribution \ref{eq:cond_state_p} is complex to retrieve in close form, for several reasons: 
\begin{itemize}
    \item The mapping between measurements and states can be highly non-linear, producing a multi-modal probability distribution with a complex shape.
    \item Each measurement $\meas_k$ in general observes only a subset of the state parameters. Moreover, the number of measurements may not be sufficient to fully characterize the state distribution.
    \item Measurements can be wrong - generating outliers - or it is impossible to map any of the state variable to a specified measurement.
\end{itemize}

However, what is possible to more easily compute is an estimate of the probability \ref{eq:cond_state_p}. To do so, we analyze the conditional distribution $p\left(\meas_k | \state\right)$: this is a predictive distribution called \textit{sensor model} or \textit{observation model}, which formalizes the probability of having a certain measurement \textit{assuming to know system's state}. Extending this to all the measurements, you will get the following distribution:

\begin{equation}
    p\left(\mathbf{z} | \mathbf{x}\right) = p\left(\meas_{1:K} | \state_{1:N}\right)
    \label{eq:likelihood}
\end{equation}

As it has been stated before, the state fully describes the measurements, rendering the single distributions $p\left(\mathbf{z}_k | \mathbf{x}\right)$ independent from each other. Exploiting this feature, it is possible to rewrite the \ref{eq:likelihood} as follows:

\begin{equation}
    \label{eq:obs_model_product}
    p\left(\meas_{1:K} | \state_{1:N}\right) = 
        \prod_{k = 1}^{K} p\left(\meas_k | \state_{1:N}\right)
\end{equation}

The equation \ref{eq:obs_model_product} describes the measurements' \textit{likelihood} given the state. Recalling the Bayes rule \cite{bayes-theorem} and applying it to \ref{eq:cond_state_p} you will obtain the following relation:

\begin{align*}
    p\left(\state_{1:N} | \meas_{1:K}\right) &= \frac{\overbracket{p\left(\meas_{1:K} | \state_{1:N}\right)}^{likelihood} \overbracket{p\left(\state_{1:N}\right)}^{prior}}{\underbracket{p\left(\meas_{1:K}\right)}_{normalizer}} = \\
    &= \frac{\prod_{k = 1}^{K} p\left(\meas_k | \state_{1:N}\right) p_x}{p_z} = \\
    &= \eta_{z} p_x \prod_{k = 1}^{K} p\left(\meas_k | \state_{1:N}\right)
\end{align*}

\noindent In this relation, $p\left(\state_{1:N}\right)$ represents our prior knowledge about the state distribution and, thus, supposing to know nothing about it, it is represented by a uniform distribution whose value is a constant $p_x$. $p\left(\meas_{1:K}\right)$ instead is just a normalizer for the overall probability function and does not depends from the states, therefore it is assumed to be a constant $p_z$. This leads to the following relation:

\begin{empheq}[box={\mybluebox[0pt]}]{equation}
    p\left(\state_{1:N} | \meas_{1:K}\right) \propto \prod_{k = 1}^{K} p\left(\meas_k | \state_{1:N}\right) 
    \label{eq:probability_proportionality}
\end{empheq}

\noindent Equation \ref{eq:probability_proportionality} represents the core of the entire least-square formulation. This will be exploited in the next subsections to approximate the distribution of interest, minimizing a defined cost function.

\subsection{Direct Minimization}
Starting from the relation \ref{eq:probability_proportionality} it is possible to initialize a minimization problem. Assuming that the measurement are affected by \textit{Additive White Gaussian Noise}, the observation model probability $p\left(\meas_k | \state_{1:N}\right)$ will be described by a Gaussian distribution $\mathcal{N}(\mu, \Omega^{-1})$, leading to the equation

\begin{equation}
    p\left(\meas_k | \state_{1:N}\right) \propto \exp\left(-(\pred_k - \meas_k) \Omega_k(\pred_k - \meas_k)\right)
    \label{eq:obs_model_probability}
\end{equation}

\noindent where $\pred_k$ is the \textbf{prediction} of the measurement given the state, while $\Omega_k = \Sigma_k^{-1}$ represents conditional measurement's information matrix. The predicted measurement $\pred_k$ is a function of the state; in particular it is obtained applying the \textbf{sensor model} $h_k(\cdot)$ to the state, in formul\ae:

\begin{equation}
    \pred_k = h_k(\state)
    \label{eq:prediction}
\end{equation}

\noindent In SLAM - and other similar problems like SfM - the sensor model is a highly non-linear function, making the problem more complex and heavy from a computational point of view. Nevertheless, generally the sensor model is smooth enough to be approximated with its \textit{first-order Taylor expansion} in the neighbor of a linearization point $\linstate$, leading to:

\begin{empheq}[box={\mybluebox[0pt]}]{equation}
    h_k(\linstate + \dx) \approx h_k(\linstate) + \frac{\partial h_k(\state)}{\partial \state} \bigg\rvert_{\state = \linstate} \dx = h_k(\linstate) + \jacob_k \dx
    \label{eq:linearization}
\end{empheq}

\noindent where $\jacob_k = \frac{\partial h_k(\state)}{\partial \state} \bigg\rvert_{\state = \linstate}$ is the \textit{Jacobian} evaluated in $\state = \linstate$.

The next step consists in finding a linearization point $\optstate$ that \textit{maximizes the observation model}, leading to the following relations:

\begin{align*}
    \optstate 	&= \argmax_\state p(\meas | \state) =\\
                &= \argmax_\state \prod_{k = 1}^{K}p(\meas_k | \state) =\\
                &= \argmax_\state \prod_{k = 1}^{K}\exp\left(-(h_k(\state) - \meas_k)^T\Omega_k(h_k(\state) - \meas_k)\right) =\\
                &= \argmin_\state \sum_{k = 1}^{K} \left((h_k(\state) - \meas_k)^T\Omega_k(h_k(\state) - \meas_k)\right)
\end{align*}

\noindent The relation $\error_k(\state) = h_k(\state) - \meas_k$ represents the \textit{error function}, and, thus, the optimal linearization point will be given by the minimization of the following \textit{cost function}:

\begin{equation}
    F(\state) = \sum_{k = 1}^ {K} \underbracket{\error_k^T(\state)\Omega_k\error_k(\state)}_{\error_k(\state)}
    \label{eq:cost_function}
\end{equation}

\noindent In order to find the optimum linearization point, the system must start from a reasonable initial guess $\linstate$ - to avoid local minima - and apply an increment $\dx$ directed toward $\optstate$. Applying the perturbation $\dx$ in the error function and approximating again through the first-order Taylor expansion we will obtain 

\begin{align}
    \error_k(\linstate + \dx) &= \left(h_k(\linstate + \dx) - \meas_k)^T \Omega_k (h_k(\linstate + \dx) - \meas_k)\right) =\nonumber\\
    &\approx (\jacob_k\dx + h_k(\linstate) - \meas_k)^T \Omega_k (\jacob_k\dx + h_k(\linstate) - \meas_k) =\nonumber\\
    &= (\jacob_k\dx + \error_k(\linstate))^T \Omega_k (\jacob_k\dx + \error_k(\linstate))
    \label{eq:error_perturbation}
\end{align}

\noindent Further expanding the quantities in the equation \ref{eq:error_perturbation}, it is possible to obtain the following relation:

\begin{align}
    \error_k(\linstate + \dx) &\approx \dx^T\overbracket{\jacob_k^T\Omega_k\jacob_k}^{H_k}\dx + 2\,\overbracket{\jacob_k^T\Omega_k\error_k(\linstate)}^{\mathbf{b}_k}\,\dx + \overbracket{\error_k^T(\linstate)\Omega_k\error_k(\linstate)}^{\mathbf{c}_k} =\nonumber\\
    &= \dx^TH_k\dx + 2\,\mathbf{b}_k\dx + \mathbf{c}_k
    \label{eq:quadratic_form_k}
\end{align}

Extending the perturbation to the total cost function expressed in equation \ref{eq:cost_function} and plugging what stated in \ref{eq:quadratic_form_k} we will obtain:

\begin{align}
    F(\linstate + \dx) &\approx \sum_{k = 1}^{K} \left[\dx^TH_k\dx + 2\,\mathbf{b}_k\dx + \mathbf{c}_k\right] =\nonumber\\
    &= \dx^T\,\underbracket{\left[\sum_{k = 1}^KH_k\right]}_{\hessian}\dx + 2\,\underbracket{\left[\sum_{k = 1}^K\mathbf{b}_k\right]}_{\mathbf{b}}\dx + \underbracket{\sum_{k = 1}^K\mathbf{c}_k}_{\mathbf{c}} \nonumber = \\
    &= \dx^T\hessian\dx + 2\,\mathbf{b}\dx + \mathbf{c}
    \label{eq:quadratic_form}
\end{align}

It is good to notice that equation \ref{eq:quadratic_form} represents a \textit{quadratic form} in $\dx$. Thus, finding the minimum of this formula will give us the optimal perturbation $\dx$ such that

\begin{equation*}
    \optstate = \linstate + \dx
\end{equation*}

\noindent In order to find the minimum of equation \ref{eq:quadratic_form} we derive it in $\dx$, we equal the derivative to zero and finally we solve the resulting equation for $\dx$; in formul\ae:

\begin{equation}
    \frac{\partial\left(\dx^T\hessian\dx + 2\,\mathbf{b}\dx + \mathbf{c}\right)}{\partial \dx} = 2\,\hessian\dx + 2\,\mathbf{b} = 0
    \label{eq:quatratic_form_derivative}
\end{equation}

\noindent Therefore, in order to find the solution of equation \ref{eq:quatratic_form_derivative} and finally get to the optimal perturbation, we must solve the following \textit{linear system}:

\begin{empheq}[box={\mybluebox[0pt]}]{equation}
\hessian\,\dx^\star = -\mathbf{b}
\label{eq:linear_system}
\end{empheq}

It is good to notice that, if the \textit{sensor model} $h_k(\cdot)$ was a linear function of the state, it was possible to find the minimum in just one iteration. However, since it is almost never the case in our cases of study, a solution must be found iteratively, until convergence is reached. To do so, it is possible to use the \textbf{Gauss-Newton} algorithm. However, algorithm is not guaranteed to converge in general. The convergence is subject to several factors, like the smoothness of the error function used or the initial guess - i.e. if it is close to potential singularity or far from the optimal solution. \textit{Levenberg-Marquardt} iterative algorithm is variation of \textit{Gauss-Newton} that enforces the convergence. It solves a \textit{damped} version of the linear system \ref{eq:linear_system}, described by the following formula:

\begin{equation}
    \left(\hessian + \lambda\mathbf{I}\right)\dx = -\mathbf{b}
    \label{eq:lm_algorithm}
\end{equation} 

\noindent where $\lambda$ is a scalar \textit{damping} factor. The algorithm does not diverge, but it may converge to a \textit{local minimum} and, thus, retrieving a sub-optimal solution. 

It is good to notice that the system developed in this work uses the \textit{Gauss-Newton} algorithm, since the error function has been properly manipulated to be more linear with respect to other approaches. Obviously, more details can be found in the next chapters.